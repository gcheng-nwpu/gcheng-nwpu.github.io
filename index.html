
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<link rel="shortcut icon" type="image/x-icon" href="photo/GongCheng.ico" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
<title>Gong CHENG</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="js/hidebib.js"></script>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-40545479-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
  
</script>

</head>


<body>
	
	
  <div class="container">
	<table width="95%" align="left" border="0" cellpadding="20">
	<A NAME="General"></A>
	<div>
    <table width="900" align="left" border="0" cellpadding="0">
    <td width="55%" valign="top">
    <p align="center">&nbsp;</p>
	<table align="left">
	<tr align="left">
	<td><ul><font color="#733a31" size="6.5px"><b>Gong Cheng &nbsp &nbsp 程塨</b></font><br></ul></td>
	</tr>
	<tr align="left">
	<td><ul><font size="4px">Professor</font></ul></td>
	</tr>
	<tr align="left">
	<td><ul><font size="4px"><a href="https://zdhxy.nwpu.edu.cn/English.htm">School of Automation</a></font></ul></td>
	</tr>
	<tr align="left">
	<td><ul><font size="4px"><a href="https://en.nwpu.edu.cn/">Northwestern Polytechnical University</a></font></ul></td>
	</tr>
	<tr align="left">
	<td><ul><font size="4px"><p> Email_1: gcheng AT nwpu.edu.cn</p></font></ul></td>
	</tr>
	<tr align="left">
	<td><ul><font size="4px"><p> Email_2: chenggong1119 AT gmail.com</p></font></ul></td>
	</tr>
	<tr align="left">
	<td><ul><font size="3.5px"><p>[<a href="https://scholar.google.com/citations?user=dw1n0vIAAAAJ&hl=en">Google Scholar</a>]
	[<a href="#Publications">Publications</a>]	
	[<a href="#Datasets">Datasets</a>]
	[<a href="https://teacher.nwpu.edu.cn/gongcheng.html">中文主页</a>]</p></font></ul></td>					
	</tr>
	</table>
    </td>
    <td width="45%">
    <div class="instructorphoto">
    <img src="photo/team.jpg" width="300" height="220">
    </div>                                                                                
    </td>
    </table>
    </table>
  </div>
  <br>


  <div class="container">
    <table width="95%" border="0" align="left" cellpadding="20">
    <A NAME="Biography"><h2 align="center"><font color="#733a31">Biography</font></h2></A>
	<div>
	<hr>
	<table width="900" align="left" border="0" cellpadding="0">
	<tr align="left">
	<td>
	<ul>
    <p style="text-align:justify; text-justify:inter-ideograph;"> Dr. Gong Cheng is a professor at <a href="https://en.nwpu.edu.cn/">Northwestern Polytechnical University</a>, Xi’an, China. 
	He received the B.S. degree from <a href="https://en.xidian.edu.cn/">Xidian University</a>, Xi’an, China, in 2007, 
	and the M.S. and Ph.D. degrees from <a href="https://en.nwpu.edu.cn/">Northwestern Polytechnical University</a>, Xi’an, China, in 2010 and 2013, respectively. 
	His main research interests are computer vision, pattern recognition, and remote sensing image analysis. 
	His publications have received more than 17,000 citations with Google Scholar, and 5 papers have been cited more than 1,000 times. 
	His 3 papers have been recognized as the China's 100 most influential international academic papers, and more than 30 papers have been recognized as ESI highly cited papers or ESI hot papers. 
	He has been awarded the following honors: <b><font color="#1772D0">IEEE GRSS Highest Impact Paper Awards</font></b> (2021, 2023), <b><font color="#1772D0">IEEE TCSVT Best Paper Award</font></b> (2021), <b><font color="#1772D0">Clarivate Highly Cited Researcher (2020-2023)</font></b>, 
	<b><font color="#1772D0">Elsevier Most Cited Chinese Researcher</font></b> (2020-2022). He is or has been an editorial board member of IEEE GRSM, IEEE TGRS, IEEE JSTARS, IEEE JMASS, ISPRS JPRS, and JRS. </p>
	</ul>
    </td>
	</tr>
	</table>
	</div>
	</table>
  </div>
  <br>

	
  <div class="container">
    <table width="95%" border="0" align="left" cellpadding="20">
    <A NAME="News"><h2 align="center"><font color="#733a31">News</font></h2></A>
	<div>
	<hr>
	<table width="900" align="left" border="0" cellpadding="0">
	<tr align="left">
	<td>
	<ul><ul type="square">
	<li><p>2024.01: One paper accepted by IJCV.</p></li>
	<li><p>2023.09: One paper accepted by IEEE TPAMI.</p></li>
        <li><p>2023.08: One paper accepted by IJCV.</p></li>
        <li><p>2023.07: One paper accepted by ICCV.</p></li>
	<li><p>2023.06: One paper accepted by IEEE TPAMI.</p></li>
	<li><p>2023.04: One paper accepted by IEEE TPAMI.</p></li>
	<li><p>2023.04: One paper published in IEEE TGRS receives the IEEE GRSS Highest Impact Paper Award.</p></li>
	<li><p>2022.07: Our team releases a large-scale <strong>S</strong>mall <strong>O</strong>bject <strong>D</strong>etection d<strong>A</strong>taset (<a href="https://shaunyuan22.github.io/SODA/">SODA</a>).</p></li>
	<li><p>2021.07: One paper published in IEEE TGRS receives the IEEE GRSS Highest Impact Paper Award.</p></li>
	<li><p>2021.05: One paper published in IEEE TSCVT receives the Best Paper Award.</p></li>
    </ul></ul>
	</td>
	</tr>
	</table>
	</div>
	</table>
  </div>
  <br>	
 
 
   <div class="container">
    <table width="95%" border="0" align="center" cellpadding="20">
    <A NAME="Publications"><h2 align="center"><font color="#733a31">Selected Publications (<a href="https://scholar.google.com/citations?user=dw1n0vIAAAAJ&hl=en">Google Scholar</a>)</font></h2></A>
	<div>
	<hr>
    <table width="900" align="left" border="0" cellpadding="0">
	<tr align="left">
	<td>
	<ul><ul type="square">
	<li><p><b>Remote Sensing Image Scene Classification: Benchmark and State of the Art</b>.<br>
	<strong>Gong Cheng</strong>, Junwei Han, Xiaoqiang Lu.<br>
	<em>Proceedings of the IEEE</em>&nbsp(<em><font color="#C00000">PIEEE</font></em>), <em>2017</em>. &nbsp [<a href="https://ieeexplore.ieee.org/document/7891544">paper</a>] [<a href="#Datasets">NWPU-RESISC45 dataset</a>]
	<div style="color: #C00000;"><p class="periodical font-italic"><i class="fa-solid fa-star"></i> Citation 2000+!</p></div>
	</p></li>
		
	<li><p><b>Towards Large-Scale Small Object Detection: Survey and Benchmarks</b>.<br>
	<strong>Gong Cheng</strong>, Xiang Yuan, Xiwen Yao, Kebing Yan, Qinghua Zeng, Xingxing Xie, Junwei Han.<br>
	<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>&nbsp(<em><font color="#C00000">IEEE TPAMI</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/document/10168277">paper</a>] [<a href="https://shaunyuan22.github.io/SODA/">project</a>]
	</p></li>
		
	<li><p><b>Holistic Prototype Activation for Few-Shot Segmentation</b>.<br>
	<strong>Gong Cheng</strong>, Chunbo Lang, Junwei Han.<br>
	<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>&nbsp(<em><font color="#C00000">IEEE TPAMI</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/document/9839487">paper</a>] [<a href="https://github.com/chunbolang/HPA">code</a>]
	</p></li>
	
	<li><p><b>Base and Meta: A New Perspective on Few-Shot Segmentation</b>.<br>
	Chunbo Lang, <strong>Gong Cheng*</strong>, Binfei Tu, Chao Li, Junwei Han.<br>
	<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>&nbsp(<em><font color="#C00000">IEEE TPAMI</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10098188">paper</a>] [<a href="https://github.com/chunbolang/BAM">code</a>]
	</p></li>

	<li><p><b>Mutual-Assistance Learning for Object Detection</b>.<br>
	Xingxing Xie#, Chunbo Lang#, Shicheng Miao#, <strong>Gong Cheng*</strong>, Ke Li, Junwei Han.<br>
	<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>&nbsp(<em><font color="#C00000">IEEE TPAMI</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10265160">paper</a>] [<a href="https://github.com/ShichengMiao16/MADet">code</a>]
	</p></li>
	
	<li><p><b>P-CNN: Part-Based Convolutional Neural Networks for Fine-Grained Visual Categorization</b>.<br>
	Junwei Han#, Xiwen Yao#, <strong>Gong Cheng*</strong>, Xiaoxu Feng, Dong Xu.<br>
	<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>&nbsp(<em><font color="#C00000">IEEE TPAMI</font></em>), <em>2022</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/8789527">paper</a>]
	</p></li>
	
	<li><p><b>Learning An Invariant and Equivariant Network for Weakly Supervised Object Detection</b>.<br>
	Xiaoxu Feng, Xiwen Yao, Hui Shen, <strong>Gong Cheng</strong>, Bin Xiao, Junwei Han.<br>
	<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>&nbsp(<em><font color="#C00000">IEEE TPAMI</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10123080">paper</a>] [<a href="https://github.com/XiaoxFeng/IENet">code</a>]
	</p></li>
	
	<li><p><b>Weakly Supervised Object Localization and Detection: A Survey</b>.<br>
	Dingwen Zhang, Junwei Han, <strong>Gong Cheng</strong>, Ming-Hsuan Yang.<br>
	<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>&nbsp(<em><font color="#C00000">IEEE TPAMI</font></em>), <em>2022</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/9409690">paper</a>]
	</p></li>
	
	<li><p><b>Adaptive Neighborhood Metric Learning</b>.<br>
	Kun Song, Junwei Han, <strong>Gong Cheng</strong>, Jiwen Lu, Feiping Nie.<br>
	<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>&nbsp(<em><font color="#C00000">IEEE TPAMI</font></em>), <em>2022</em>.  [<a href="https://ieeexplore.ieee.org/abstract/document/9405473">paper</a>]
	</p></li>

	<li><p><b>Oriented R-CNN and Beyond</b>.<br>
	Xingxing Xie, <strong>Gong Cheng*</strong>, Jiabao Wang, Ke Li, Xiwen Yao, Junwei Han.<br>
	<em>International Journal of Computer Vision</em>&nbsp(<em><font color="#C00000">IJCV</font></em>), <em>2024</em>. [<a href="https://link.springer.com/article/10.1007/s11263-024-01989-w">paper</a>] [<a href="https://github.com/jbwang1997/OBBDetection">code</a>]
	</p></li>
		
	<li><p><b>Few-Shot Segmentation via Divide-and-Conquer Proxies</b>.<br>
	Chunbo Lang, <strong>Gong Cheng*</strong>, Binfei Tu, Junwei Han.<br>
	<em>International Journal of Computer Vision</em>&nbsp(<em><font color="#C00000">IJCV</font></em>), <em>2023</em>. [<a href="https://link.springer.com/article/10.1007/s11263-023-01886-8">paper</a>] [<a href="https://github.com/chunbolang/DCP">code</a>]
	</p></li>
		
	<li><p><b>Small object detection via coarse-to-fine proposal generation and imitation learning</b>.<br>
	Xiang Yuan, <strong>Gong Cheng*</strong>, Kebing Yan, Qinghua Zeng, Junwei Han.<br>
	<em>IEEE International Conference on Computer Vision</em>&nbsp(<em><font color="#C00000">ICCV</font></em>), <em>2023</em>. [<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Small_Object_Detection_via_Coarse-to-fine_Proposal_Generation_and_Imitation_Learning_ICCV_2023_paper.html">paper</a>] [<a href="https://github.com/shaunyuan22/CFINet">code</a>]
	</p></li>	

	<li><p><b>Exploring Effective Data for Surrogate Training Towards Black-Box Attack</b>.<br>
	Xuxiang Sun, <strong>Gong Cheng*</strong>, Hongda Li, Lei Pei, Junwei Han.<br>
	<em>IEEE Conference on Computer Vision and Pattern Recognition</em>&nbsp(<em><font color="#C00000">CVPR</font></em>), <em>2022</em>. [<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Exploring_Effective_Data_for_Surrogate_Training_Towards_Black-Box_Attack_CVPR_2022_paper.html">paper</a>] [<a href="https://github.com/xuxiangsun/ST-Data">code</a>] 
	</p></li>
	
	<li><p><b>Learning What Not to Segment: A New Perspective on Few-Shot Segmentation</b>.<br>
	Chunbo Lang, <strong>Gong Cheng*</strong>, Binfei Tu, Junwei Han.<br>
	<em>IEEE Conference on Computer Vision and Pattern Recognition</em>&nbsp(<em><font color="#C00000">CVPR</font></em>), <em>2022</em>. [<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Lang_Learning_What_Not_To_Segment_A_New_Perspective_on_Few-Shot_CVPR_2022_paper.html">paper</a>] [<a href="https://github.com/chunbolang/BAM">code</a>] 
	</p></li>
	
	<li><p><b>Beyond the Prototype: Divide-and-Conquer Proxies for Few-Shot Segmentation</b>.<br>
	Chunbo Lang#, Binfei Tu#, <strong>Gong Cheng*</strong>, Junwei Han.<br>
	<em>International Joint Conference on Artificial Intelligence</em>&nbsp(<em><font color="#C00000">IJCAI</font></em>), <em>2022</em>. [<a href="https://arxiv.org/abs/2204.09903">paper</a>] [<a href="https://github.com/chunbolang/DCP">code</a>] 
	</p></li>

	<li><p><b>Oriented R-CNN for Object Detection</b>.<br>
	Xingxing Xie, <strong>Gong Cheng*</strong>, Jiabao Wang, Xiwen Yao, Junwei Han.<br>
	<em>IEEE International Conference on Computer Vision</em>&nbsp(<em><font color="#C00000">ICCV</font></em>), <em>2021</em>. [<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Xie_Oriented_R-CNN_for_Object_Detection_ICCV_2021_paper.html">paper</a>] [<a href="https://github.com/jbwang1997/OBBDetection">code</a>]
	</p></li>	
		
	<li><p><b>NCSiam: Reliable Matching via Neighborhood Consensus for Siamese-Based Object Tracking</b>.<br>
	Pujian Lai, <strong>Gong Cheng*</strong>, Meili Zhang, Jifeng Ning, Xiangtao Zheng, Junwei Han.<br>
	<em>IEEE Transactions on Image Processing</em>&nbsp(<em><font color="#C00000">IEEE TIP</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/document/10313240/">paper</a>] [<a href="https://github.com/laybebe/NCSiam">code</a>]
	</p></li>
		
	<li><p><b>On Single-Model Transferable Targeted Attacks: A Closer Look at Decision-Level Optimization</b>.<br>
	Xuxiang Sun, <strong>Gong Cheng*</strong>, Hongda Li, Lei Pei, Junwei Han.<br>
	<em>IEEE Transactions on Image Processing</em>&nbsp(<em><font color="#C00000">IEEE TIP</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10129225">paper</a>] [<a href="https://github.com/xuxiangsun/DLLTTAA">code</a>]
	</p></li>

	<li><p><b>Retain and Recover: Delving into Information Loss for Few-Shot Segmentation</b>.<br>
	Chunbo Lang, <strong>Gong Cheng*</strong>, Binfei Tu, Chao Li, Junwei Han.<br>
	<em>IEEE Transactions on Image Processing</em>&nbsp(<em><font color="#C00000">IEEE TIP</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10256677">paper</a>] [<a href="https://github.com/chunbolang/RARE">code</a>]
	</p></li>

	<li><p><b>High-quality proposals for weakly supervised object detection</b>.<br>
	<strong>Gong Cheng</strong>, Junyu Yang, Decheng Gao, Lei Guo, Junwei Han.<br>
	<em>IEEE Transactions on Image Processing</em>&nbsp(<em><font color="#C00000">IEEE TIP</font></em>), <em>2020</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/9069411">paper</a>] [<a >code</a>]
	</p></li>

	<li><p><b>Learning rotation-invariant and Fisher discriminative convolutional neural networks for object detection</b>.<br>
	<strong>Gong Cheng</strong>, Junwei Han, Peicheng Zhou, Dong Xu.<br>
	<em>IEEE Transactions on Image Processing</em>&nbsp(<em><font color="#C00000">IEEE TIP</font></em>), <em>2019</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/8445665">paper</a>] [<a >code</a>]
	</p></li>

	<li><p><b>Duplex metric learning for image set classification</b>.<br>
	<strong>Gong Cheng</strong>, Peicheng Zhou, Junwei Han.<br>
	<em>IEEE Transactions on Image Processing</em>&nbsp(<em><font color="#C00000">IEEE TIP</font></em>), <em>2018</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/8060589">paper</a>] [<a >code</a>]
	</p></li>	
		
	<li><p><b>Cross-Level Attentive Feature Aggregation for Change Detection</b>.<br>
	Guangxing Wang, <strong>Gong Cheng*</strong>, Peicheng Zhou, Junwei Han.<br>
	<em>IEEE Transactions on Circuits and Systems for Video Technology</em>&nbsp(<em><font color="#C00000">IEEE TCSVT</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10364762">paper</a>] [<a href="https://github.com/xingronaldo/CLAFA">code</a>]
	</p></li>
		
	<li><p><b>Boosting Knowledge Distillation via Intra-class Logit Distribution Smoothing</b>.<br>
	Cong Li, <strong>Gong Cheng*</strong>, Junwei Han.<br>
	<em>IEEE Transactions on Circuits and Systems for Video Technology</em>&nbsp(<em><font color="#C00000">IEEE TCSVT</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/document/10292885">paper</a>] [<a href="https://github.com/swift1988">code</a>]
	</p></li>

	<li><p><b>A Unified Metric Learning-Based Framework for Co-Saliency Detection</b>.<br>
	Junwei Han, <strong>Gong Cheng*</strong>, Zhenpeng Li, Dingwen Zhang*.<br>
	<em>IEEE Transactions on Circuits and Systems for Video Technology</em>&nbsp(<em><font color="#C00000">IEEE TCSVT</font></em>), <em>2018</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/7932195">paper</a>] [<a href="https://pan.baidu.com/share/init?surl=o2jHpIumfyMeyHXvum_axw#list/path=%2F">code</a>]<br>
	(<b><font color="#1772D0">2021 IEEE TCSVT Best Paper Award</font></b>)
	</p></li>	

	<li><p><b>Class Attention Network for Image Recognition</b>.<br>
	<strong>Gong Cheng</strong>, Pujian Lai, Decheng Gao, Junwei Han.<br>
	<em>SCIENCE CHINA Information Sciences</em>&nbsp(<em><font color="#C00000">SCIS</font></em>), <em>2023</em>. [<a href="https://link.springer.com/article/10.1007/s11432-021-3493-7">paper</a>] [<a href="https://github.com/laybebe/CANet">code</a>]
	</p></li>
		
	<li><p><b>Fewer Is More: Efficient Object Detection in Large Aerial Images</b>.<br>
	Xingxing Xie, <strong>Gong Cheng*</strong>, Qingyang Li, Shicheng Miao, Ke Li, Junwei Han.<br>
	<em>SCIENCE CHINA Information Sciences</em>&nbsp(<em><font color="#C00000">SCIS</font></em>), <em>2023</em>. [<a href="https://www.sciengine.com/SCIS/doi/10.1007/s11432-022-3718-5;JSESSIONID=5824e31a-89b1-49e5-8a77-0b6d4c796fbb">paper</a>] [<a href="https://github.com/Ranchosky/OAN">code</a>]
	</p></li>

	<li><p><b>Attention Erasing and Instance Sampling for Weakly Supervised Object Detection</b>.<br>
	Xuan Xie, <strong>Gong Cheng*</strong>, Xiaoxu Feng, Xiwen Yao, Xiaoliang Qian, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10345589">paper</a>] [<a href="https://github.com/XuanX/AE-IS">code</a>]
	</p></li>
		
	<li><p><b>Target-aware Transformer for Satellite Video Object Tracking</b>.<br>
	Pujian Lai, Meili Zhang, <strong>Gong Cheng*</strong>, Shengyang Li, Xiankai Huang, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10342836">paper</a>] [<a href="https://github.com/laybebe/TATrans_SVOT">code</a>]
	</p></li>
		
	<li><p><b>Global rectification and decoupled registration for few-shot segmentation in remote sensing imagery</b>.<br>
	Chunbo Lang, <strong>Gong Cheng*</strong>, Binfei Tu, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10201464">paper</a>] [<a href="https://github.com/chunbolang/R2Net">code</a>]
	</p></li>
		
	<li><p><b>Learning Orientation-aware Distances for Oriented Object Detection</b>.<br>
	Chaofan Rao#, Jiabao Wang#, <strong>Gong Cheng*</strong>, Xingxing Xie, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10130561">paper</a>] [<a href="https://github.com/DDGRCF/FCOSF">code</a>]
	</p></li>
	
	<li><p><b>SFRNet: Fine-Grained Oriented Object Recognition via Separate Feature Refinement</b>.<br>
	<strong>Gong Cheng</strong>, Qingyang Li, Guangxing Wang, Xingxing Xie, Lingtong Min, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10129210">paper</a>] [<a href="https://github.com/Ranchosky/SFRNet">code</a>]
	</p></li>
	
	<li><p><b>Threatening Patch Attacks on Object Detection in Optical Remote Sensing Images</b>.<br>
	Xuxiang Sun, <strong>Gong Cheng*</strong>, Lei Pei, Hongda Li, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10119208">paper</a>] [<a href="https://github.com/plpl2019/TPA">code</a>]
	</p></li>
	
	<li><p><b>Instance-Aware Distillation for Efficient Object Detection in Remote Sensing Images</b>.<br>
	Cong Li, <strong>Gong Cheng*</strong>, Guangxing Wang, Peicheng Zhou, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/10024393">paper</a>] [<a href="https://github.com/swift1988/InsDist">code</a>]
	</p></li>
	
	<li><p><b>On Improving Bounding Box Representations for Oriented Object Detection</b>.<br>
	Yanqing Yao, <strong>Gong Cheng*</strong>, Guangxing Wang, Shengyang Li, Peicheng Zhou, Xingxing Xie, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2023</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/9996428">paper</a>] [<a href="https://github.com/yanqingyao1994/QPDet">code</a>]
	</p></li>
	
	<li><p><b>Anchor-Free Oriented Proposal Generator for Object Detection</b>.<br>
	<strong>Gong Cheng</strong>, Jiabao Wang, Ke Li, Xingxing Xie, Chunbo Lang, Yanqing Yao, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2022</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/9795321">paper</a>] [<a href="https://github.com/jbwang1997/AOPG">code</a>] [<a href="#Datasets">DIOR-R dataset</a>]
	</p></li>
	
	<li><p><b>ISNet: Towards Improving Separability for Remote Sensing Image Change Detection</b>.<br>
	<strong>Gong Cheng</strong>, Guangxing Wang, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2022</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/9772654">paper</a>] [<a href="https://github.com/xingronaldo/ISNet">code</a>]
	</p></li>
	
	<li><p><b>Dual-Aligned Oriented Detector</b>.<br>
	<strong>Gong Cheng</strong>, Yanqing Yao, Shengyang Li, Ke Li, Xingxing Xie, Jiabao Wang, Xiwen Yao, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2022</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/9706434">paper</a>] [<a href="https://github.com/yanqingyao1994/DODet">code</a>]
	</p></li>
	
	<li><p><b>Prototype-CNN for Few-Shot Object Detection in Remote Sensing Images</b>.<br>
	<strong>Gong Cheng</strong>, Bowei Yan, Peizhen Shi, Ke Li, Xiwen Yao, Lei Guo, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2022</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/9435769">paper</a>] [<a href="https://github.com/Ybowei/P-CNN">code</a>]
	</p></li>
	
	<li><p><b>SPNet: Siamese-Prototype Network for Few-Shot Remote Sensing Image Scene Classification</b>.<br>
	<strong>Gong Cheng</strong>, Liming Cai, Chunbo Lang, Xiwen Yao, Jinyong Chen, Lei Guo, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2022</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/9501951">paper</a>] [<a href="https://github.com/zoraup/SPNet">code</a>]
	</p></li>
	
	<li><p><b>Perturbation-Seeking Generative Adversarial Networks: A Defense Framework for Remote Sensing Image Scene Classification</b>.<br>
	<strong>Gong Cheng</strong>, Xuxiang Sun, Ke Li, Lei Guo, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2022</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/9442932">paper</a>] [<a href="https://github.com/xuxiangsun/PSGAN">code</a>]
	</p></li>
	
	<li><p><b>Object Detection in Optical Remote Sensing Images: A Survey and A New Benchmark</b>.<br>
	Ke Li, Gang Wan, <strong>Gong Cheng*</strong>, Liqiu Meng, Junwei Han*.<br>
	<em>ISPRS Journal of Photogrammetry and Remote Sensing</em>&nbsp(<em><font color="#C00000">ISPRS JPRS</font></em>), <em>2020</em>. [<a href="https://www.sciencedirect.com/science/article/pii/S0924271619302825">paper</a>] [<a href="#Datasets">DIOR dataset</a>]
	</p></li>
	
	<li><p><b>When Deep Learning Meets Metric Learning: Remote Sensing Image Scene Classification via Learning Discriminative CNNs</b>.<br>
	<strong>Gong Cheng</strong>, Ceyuan Yang, Xiwen Yao, Lei Guo, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2018</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/8252784">paper</a>] [<a href="https://github.com/limbo0000/PairLoss">code</a>]<br>
	(<b><font color="#1772D0">2023 IEEE GRSS Highest Impact Paper Award</font></b>)
	</p></li>

	<li><p><b>Exploring hierarchical convolutional features for hyperspectral image classification</b>.<br>
	<strong>Gong Cheng</strong>, Zhenpeng Li, Junwei Han, Xiwen Yao, Lei Guo.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2018</em>. &nbsp [<a href="https://ieeexplore.ieee.org/abstract/document/8393448">paper</a>] [<a href="https://pan.baidu.com/s/1DLJbjMNY6WnvV9U2R-dGew">code</a>]
	</p></li>
		
	<li><p><b>Rotation-insensitive and context-augmented object detection in remote sensing images</b>.<br>
	Ke Li, <strong>Gong Cheng*</strong>, Shuhui Bu, Xiong You.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2018</em>. &nbsp [<a href="https://ieeexplore.ieee.org/abstract/document/8240988">paper</a>] [<a href="https://pan.baidu.com/s/1PUhRxDDqUN2cr3tDyXvasw">NWPU VHR-10.v2 dataset</a>]
	</p></li>
		
	<li><p><b>Learning Rotation-Invariant Convolutional Neural Networks for Object Detection in VHR Optical Remote Sensing Images</b>.<br>
	<strong>Gong Cheng</strong>, Peicheng Zhou, Junwei Han.<br>
	<em>IEEE Transactions on Geoscience and Remote Sensing</em>&nbsp(<em><font color="#C00000">IEEE TGRS</font></em>), <em>2016</em>. [<a href="https://ieeexplore.ieee.org/abstract/document/7560644">paper</a>] [<a href="https://pan.baidu.com/s/158JPjYQvXwnkrAqKF72Jgg#list/path=%2F">code</a>]<br>
	(<b><font color="#1772D0">2021 IEEE GRSS Highest Impact Paper Award</font></b>)
	</p></li>
	
	</ul></ul>
	</td>
	</tr>
	</table>
	</div>
	</table>
  </div>
  <br>

	    

  <div class="container">
    <table width="95%" border="0" align="center" cellpadding="20">
    <A NAME="Datasets"><h2 align="center"><font color="#733a31">Datasets</font></h2></A>
	<div>
	<hr>
    <table width="900" align="left" border="0" cellpadding="0">
	<tr align="left">
    <td>
	<ul><ul type="square">
    <li><p align="left"><b><font color="#930000", size="4.5px">NWPU-RESISC45 dataset</font></b></p></li></ul></ul>
	<ul><ul><p style="text-align:justify; text-justify:inter-ideograph;"><b>NWPU-RESISC45 dataset</b> is a publicly available benchmark for REmote Sensing Image Scene Classification (RESISC), 
	created by Northwestern Polytechnical University (NWPU). This dataset contains 31,500 images, covering 45 scene 
	classes with 700 images in each class. These 45 scene classes include airplane, airport, baseball diamond, 
	basketball court, beach, bridge, chaparral, church, circularfarmland, cloud, commercial area, dense residential, 
	desert, forest, freeway, golf course, ground track field, harbor, industrial area, intersection, island, lake, 
	meadow, medium residential, mobile home park, mountain, overpass, palace, parking lot, railway, railway station, 
	rectangular farmland, river, roundabout, runway, sea ice, ship, snowberg, sparse residential, stadium, 
	storage tank, tennis court, terrace, thermal power station, and wetland.</p>
	<p align="left">Please cite the following paper when you use this dataset fully or partly:</p>
	<p style="text-align:justify; text-justify:inter-ideograph"><span><b>Gong Cheng</b>, Junwei Han, Xiaoqiang Lu. Remote Sensing Image Scene Classification: Benchmark and State of the Art.
	Proceedings of the IEEE, 105(10): 1865-1883, 2017.</span></p>
	<p align="left">This dataset can be downloaded from <a href="https://1drv.ms/u/s!AmgKYzARBl5ca3HNaHIlzp_IXjs">OneDrive</a> or <a href="https://pan.baidu.com/s/1mifR6tU">BaiduNetDisk</a>.</p></ul></ul><br>		
	</td>
	</tr>
	
	<tr align="left">
	<td>
	<ul><ul type="square">
    <li><p align="left"><b><font color="#930000", size="4.5px">DIOR and DIOR-R datasets</font></b></p></li></ul></ul>
	<ul><ul><p style="text-align:justify; text-justify:inter-ideograph;"><b>"DIOR"</b> is a large-scale benchmark dataset
	for object detection in optical remote sensing images, which consists of 23,463 images and 192,518 object instances annotated with horizontal bounding boxes.</p>
	<p style="text-align:justify; text-justify:inter-ideograph;"><b>"DIOR-R"</b> is an extended version of DIOR annotated with oriented bounding boxes, which shares the same images with DIOR.</p>
	<p align="left">Please cite the following paper when you use the dataset fully or partly:</p>
	<p align="left", style="text-align:justify; text-justify:inter-ideograph"><span>Ke Li, Gang Wan, <b>Gong Cheng*</b>, Liqiu Meng, Junwei Han*. Object detection in optical remote sensing images: a survey and a new benchmark. ISPRS Journal of Photogrammetry and Remote Sensing, 159: 296-307, 2020.</span></p>
	<p align="left", style="text-align:justify; text-justify:inter-ideograph"><span><b>Gong Cheng</b>, Jiabao Wang, Ke Li, Xingxing Xie, Chunbo Lang, Yanqing Yao, Junwei Han. Anchor-free Oriented Proposal Generator for Object Detection. IEEE Transactions on Geoscience and Remote Sensing, 2022.</span></p>
	<p align="left">The dataset can be downloaded from <a href="https://drive.google.com/open?id=1UdlgHk49iu6WpcJ5467iT-UqNPpx__CC">Google Drive</a> or <a href="https://pan.baidu.com/s/1iLKT0JQoKXEJTGNxt5lSMg">BaiduNetDisk</a>.</p></ul></ul><br>
	</td>
	</tr>
	
	<tr align="left">
	<td>
	<ul><ul type="square">
	<li><p align="left"><b><font color="#930000", size="4.5px">NWPU VHR-10 dataset</font></b></p></li></ul></ul>
	<ul><ul><p style="text-align:justify; text-justify:inter-ideograph;"><b>NWPU VHR-10 dataset</b> is a publicly available 10-class geospatial object detection dataset 
	used for research purposes only. These ten classes of objects are airplane, ship, storage tank, baseballdiamond, 
	tennis court, basketball court, ground track field, harbor, bridge, and vehicle. This dataset contains totally 800 
	very-high-resolution (VHR) remote sensing images that were cropped from Google Earth and Vaihingen dataset 
	and then manually annotated by experts.</p>
	<p align="left">Please cite the following papers when you use this dataset fully or partly:</p>
	<p align="left", style="text-align:justify; text-justify:inter-ideograph"><span><b>Gong Cheng</b>, Junwei Han, Peicheng Zhou, Lei Guo. Multi-class geospatial object detection and geographic image classification based on collection of part detectors. ISPRS Journal of Photogrammetry and Remote Sensing, 98: 119-132, 2014.</span></p>
	<p align="left", style="text-align:justify; text-justify:inter-ideograph"><span><b>Gong Cheng</b>, Junwei Han. A survey on object detection in optical remote sensing images. ISPRS Journal of Photogrammetry and Remote Sensing, 117: 11-28, 2016.</span></p>
	<p align="left", style="text-align:justify; text-justify:inter-ideograph"><span><b>Gong Cheng</b>, Peicheng Zhou, Junwei Han. Learning rotation-invariant convolutional neural networks for object detection in VHR optical remote sensing images. IEEE Transactions on Geoscience and Remote Sensing, 54(12): 7405-7415, 2016.</span></p>
	<p align="left">This dataset can be downloaded from <a href="https://1drv.ms/u/s!AmgKYzARBl5cczaUNysmiFRH4eE">OneDrive</a> or <a href="https://pan.baidu.com/s/1hqwzXeG">BaiduNetDisk</a>.</p></ul></ul><br>	
	</td>
	</tr>
	     
	<tr align="left">
	<td>
	<ul><ul type="square">
	<li><p align="left"><b><font color="#930000", size="4.5px">MAR20 dataset</font></b></p></li></ul></ul>
	<ul><ul><p style="text-align:justify; text-justify:inter-ideograph;"><b>MAR20 dataset</b> is a publicly available remote sensing image Military Aircraft Recognition dataset 
	used for research purposes only. This dataset includes 3842 images, 20 types, and 22341 instances annotated with horizontal bounding boxes and oriented bounding boxes.</p>
	<p align="left">Please cite the following paper when you use this dataset fully or partly:</p>
	<p align="left", style="text-align:justify; text-justify:inter-ideograph"><span>Wenqi Yu, <b>Gong Cheng</b>, Meijun Wang, Yanqing Yao, Xingxing Xie, Xiwen Yao, Junwei Han. MAR20: A Benchmark for Military Aircraft Recognition in Remote Sensing Images. Journal of Remote Sensing (Chinese), 2022.</span></p>
	<p align="left">This dataset can be downloaded from <a href="https://1drv.ms/u/s!AmgKYzARBl5ceGUKiVsRzfxZa_4?e=K21Spg">OneDrive</a> or <a href="https://pan.baidu.com/s/1VpQGGoSVTdFCtROVnH4s3A?pwd=wye2">BaiduNetDisk</a>.</p></ul></ul><br>	
	</td>
	</tr>
	
	<tr>
	<td>
	<p style="text-align:right;"><em><font size="1.5">borrowed from <a href="https://jonbarron.info/">Jon Barron</a> & <a href="https://gkioxari.github.io/">Georgia Gkioxari</a></font></em></p>
	</td>
	</tr>
	
    </table>
    </div>
    </table>
  </div>
  <br>


<p align="center"><a href="https://info.flagcounter.com/gdW3"><img src="https://s04.flagcounter.com/count2/gdW3/bg_FFFFFF/txt_000000/border_CCCCCC/columns_6/maxflags_12/viewers_0/labels_0/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a></p>

  		  
		  
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
          
</body>
</html>
